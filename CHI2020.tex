\documentclass{sigchi}

% Use this section to set the ACM copyright statement (e.g. for
% preprints).  Consult the conference website for the camera-ready
% copyright statement.

% Copyright
\CopyrightYear{2020}
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
% DOI
\doi{https://doi.org/10.1145/3313831.XXXXXXX}
% ISBN
\isbn{978-1-4503-6708-0/20/04}
%Conference
\conferenceinfo{CHI'20,}{April  25--30, 2020, Honolulu, HI, USA}
%Price
\acmPrice{\$15.00}

% Use this command to override the default ACM copyright statement
% (e.g. for preprints).  Consult the conference website for the
% camera-ready copyright statement.

%% HOW TO OVERRIDE THE DEFAULT COPYRIGHT STRIP --
%% Please note you need to make sure the copy for your specific
%% license is used here!
% \toappear{
% Permission to make digital or hard copies of all or part of this work
% for personal or classroom use is granted without fee provided that
% copies are not made or distributed for profit or commercial advantage
% and that copies bear this notice and the full citation on the first
% page. Copyrights for components of this work owned by others than ACM
% must be honored. Abstracting with credit is permitted. To copy
% otherwise, or republish, to post on servers or to redistribute to
% lists, requires prior specific permission and/or a fee. Request
% permissions from \href{mailto:Permissions@acm.org}{Permissions@acm.org}. \\
% \emph{CHI '16},  May 07--12, 2016, San Jose, CA, USA \\
% ACM xxx-x-xxxx-xxxx-x/xx/xx\ldots \$15.00 \\
% DOI: \url{http://dx.doi.org/xx.xxxx/xxxxxxx.xxxxxxx}
% }

% Arabic page numbers for submission.  Remove this line to eliminate
% page numbers for the camera ready copy
% \pagenumbering{arabic}

% Load basic packages
\usepackage{balance}       % to better equalize the last page
\usepackage{graphics}      % for EPS, load graphicx instead 
\usepackage[T1]{fontenc}   % for umlauts and other diaeresis
\usepackage{txfonts}
\usepackage{mathptmx}
\usepackage[pdflang={en-US},pdftex]{hyperref}
\usepackage{color}
\usepackage{booktabs}
\usepackage{textcomp}

% Some optional stuff you might like/need.
\usepackage{microtype}        % Improved Tracking and Kerning
% \usepackage[all]{hypcap}    % Fixes bug in hyperref caption linking
\usepackage{ccicons}          % Cite your images correctly!
% \usepackage[utf8]{inputenc} % for a UTF8 editor only

% If you want to use todo notes, marginpars etc. during creation of
% your draft document, you have to enable the "chi_draft" option for
% the document class. To do this, change the very first line to:
% "\documentclass[chi_draft]{sigchi}". You can then place todo notes
% by using the "\todo{...}"  command. Make sure to disable the draft
% option again before submitting your final document.
\usepackage{todonotes}

%
\usepackage{gensymb}
%

% Paper metadata (use plain text, for PDF inclusion and later
% re-using, if desired).  Use \emtpyauthor when submitting for review
% so you remain anonymous.
\def\plaintitle{CollaboVR: A Reconfigurable Framework for Multi-user to Communicate in Virtual}
\def\plainauthor{Zhenyi He, Ken Perlin}
\def\emptyauthor{}
\def\plainkeywords{Virtual Reality; free-hand drawing; computer-supported collaborative work.}
\def\plaingeneralterms{Documentation, Standardization}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{
    \def\UrlFont{\sf}
  }{
    \def\UrlFont{\small\bf\ttfamily}
  }}
\makeatother
\urlstyle{leo}

% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, to give it a
% fighting chance of not being over-written, since its job is to
% redefine many LaTeX commands.
\definecolor{linkColor}{RGB}{6,125,233}
\hypersetup{%
  pdftitle={\plaintitle},
% Use \plainauthor for final version.
%  pdfauthor={\plainauthor},
  pdfauthor={\emptyauthor},
  pdfkeywords={\plainkeywords},
  pdfdisplaydoctitle=true, % For Accessibility
  bookmarksnumbered,
  pdfstartview={FitH},
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=linkColor,
  breaklinks=true,
  hypertexnames=false
}

% create a shortcut to typeset table headings
% \newcommand\tabhead[1]{\small\textbf{#1}}

% End of preamble. Here it comes the document.
\begin{document}

\title{\plaintitle}

\numberofauthors{3}
\author{%
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
}

 \teaser{
 \includegraphics[width=0.8\paperwidth]{figures/sigchi-logo}
  \caption{Insert a caption below each figure. Do not alter the
    Caption style.  One-line captions should be centered; multi-line
    should be justified. }~\label{fig:figureT}
 } 
 
\maketitle

\begin{abstract}
  Despite various collaborative software that supports expressing ideas, people still largely prefer physical notebooks or whiteboards. The reason is that they provide free-form expressions, co-presence of all participants and easy collaboration. However, when working with remote participants, people often choose the convenience of video conferencing, perhaps with screen sharing. We propose CollaboVR, an open-source reconfigurable framework for distributed and co-located multi-user communication in Virtual Reality. We tested CollaboVR with an application that lets participants create freehand drawings and 3D objects, while allowing participants to adjust two key variables: (1) User arrangement (participants adjust the location of their views of other participants) and (2) Input orientation (participants adjust the input to be vertical or horizontal). Preliminary user studies show that CollaboVR is a useful collaborative tool. Users report that some user arrangements and input orientations work best for brainstorming, while others work best for presentation or collaborative refinement of designs.
\end{abstract}


% ACM Classfication

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003120.10003121.10003124.10010866</concept_id>
<concept_desc>Human-centered computing~Virtual reality</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003120.10003121.10003124.10011751</concept_id>
<concept_desc>Human-centered computing~Collaborative interaction</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Virtual reality}
\ccsdesc[500]{Human-centered computing~Collaborative interaction}

% Author Keywords
\keywords{\plainkeywords}

% Print the classficiation codes
%\printccsdesc
%Please use the 2012 Classifiers and see this link to embed them in the text: \url{https://dl.acm.org/ccs/ccs_flat.cfm}



\section{Introduction}
% VR for workspace and collaboration, however the communication layer still remain the same for most of them
% communication work. Workspace awareness is one important key. -- user arrangement design
% Inspired by taxomony and other tabletop work, we proposed ... a reconfigurable ... to see how mid-air visual aids work and how the two vars affect the experience
% List all the contributions
Virtual Reality (VR) is being explored increasingly, spurred by the availability of high quality consumer headsets in recent years. VR enables rich design spaces in HCI by providing 3D input and immersive experiences. In 1998, an idea, the "Office of the future," was proposed to enable remotely located people to feel as though they were together in a shared office space~\cite{raskar1998office}, via a hybrid of modalities including telepresence, large panoramic displays and manipulation of shared 3D objects. The core idea was that VR had the potential to enhance communication and collaboration among groups of people, as well as Augmented Reality (AR) and projection-based immersive experience. Since then, significant progress has been made in exploring techniques for communication~\cite{ishii1993integration, otsuka2016mmspace}, collaborative works~\cite{kunert2014photoportals,tang2010three}, infrastructure~\cite{maimone2013general, o2011blended, thomas2014muvr} and various modalities~\cite{follmer2013inform, leithinger2014physical, leithinger2015shape, nakagaki2019inforce} for multi-user experiences. However, we found quite a few work are still using 2D audio as the only direct communication method during the collaborative immersive experience~\cite{xia2018spacetime}, let alone some work only provide indirect communication approach such as changing the color of the shared target~\cite{huo2018synchronizar}. In this work, we consider designing a VR communication framework which could be potentially benefited from by collaborative experiences.

% How other ppl contribute to related area, communication/collaboration/co-located and distributed
Quite a few work contributed to improving communication through VR/AR or tabletops for co-located and distributed groups. Observed by Lindemann ~\cite{tversky2003human}, we commonly use gestures or visual aids while speaking to others in daily life. Technically, being aware of these behaviors is part of \textit{workspace awareness}, defined as the up-to-the-moment understanding of other person's interaction with a shared workspace~\cite{li2014interactive}. Providing workspace awareness is widely applied on many works. 
%Prior work tried to improve communication using alternative arrangements of spaces and enhanced digital content for communication. 
One trend is enabling face-to-face interaction during communication through shared display, such as VideoDraw~\cite{tang1990videodraw}, ClearBoard~\cite{ishii1993integration} and FacingBoard~\cite{li2014interactive}. In addition, MMSpace implemented kinetic display avatars so the displays can change self-orientation to realize face-to-face interaction for different participants accordingly~\cite{otsuka2016mmspace}. Besides, traditional setup including white-boards and side-by-side projected displays improved group performance as well~\cite{plaue2009presence}. Another trend is using tabletop tangible devices~\cite{brave1998tangible, kunert2019multi}. 
This setup also provides the co-presence of the other people in the group. Inspired by the previous works, we propose to support different options for user arrangement (how participants adjust the views of other participants) and input orientation (how participants adjust the angle of the input plane).

We propose CollaboVR, an open-source reconfigurable framework for distributed and co-located multi-user communication in VR. The framework includes:
\begin{itemize}
    \item A protocol: connect the portable application to the system. To provide rich and smart visual aids, we choose Chalktalk (an open-source digital presentation and communication language) to support free-hand drawing and 3D objects~\cite{perlin2018chalktalk}. More details will be described later.
    \item A star network: to connect all distributed clients with each other through the server.
    \item Rich interactions on manipulating the drawings: all the visual aids (free-hand drawing or 3D objects) could be further manipulated after being drawn.
    \item Multiple user arrangement: participants can adjust the location of their views of other participants.
    \item Multiple input orientation: participants can adjust the angle of input area.
\end{itemize}

Our main contributions in this papers are:
\begin{enumerate}
    \item Designing and implementing an open-source reconfigurable framework for multi-user communication. The code will be made available \url{masked For Anonymity}.
    \item A system evaluation indicates that CollaboVR is a useful collaborative tool in terms of communication.
    \item Qualitative feedback indicates that different combinations of two key variables (user arrangement and input orientation) work differently for communication in terms of different collaborative purposes.
\end{enumerate}

\section{Scenario[opt]}

\section{Related Work}
% not smooth
CollaboVR is a framework to assist communication. By definition, communication is an act of expressing and understanding among a group. This is quite similar to \textit{sensemaking}: understanding the meaning~\cite{paul2009understanding}. Sensemaking is a concept widely researched in information visualization area recently. Dervin describes sensemaking as using ideas, emotions and memories to bridge a gap in understanding in group~\cite{dervin1992mind}. Learning how collaborative sensemaking is supported through different design considerations is very inspiring for multi-user communication. In next section, we will introduce collaborative sensemaking approaches first. Second, we will introduce that workspace awareness has positive effects on collaboration and how previous works enhance workspace awareness. Lastly, we will introduce immersive collaboration and communication as well as their gains and limitations.

\subsection{Collaborative Sensemaking}
%introduce the definition of sensemaking somewhere and how we deal with it
Quite a few work have researched sensemaking in different domains in CHI and CSCW area~\cite{albolino2007sensemaking, billman2007medical, landgren2007study,paul2009understanding}. Given that sensemaking involves data analyze~\cite{yi2008understanding}, different designs of 2D displays and digital tabletop are discussed a lot. First, large and shared displays have been shown to benefit sensemaking groups in a number of contexts. Sharodal designed CoSense~\cite{dervin1992mind} with a shared display, conducted an ethnographic study, and examined how collaborative sensemaking can be supported. Moreover, Vogt et al. found that the large display facilitated the paired sensemaking process, allowing teams to spatially arrange information and conduct individual work as needed~\cite{vogt2011co}. Similarly, multiple digital tabletops were used for sensemaking tasks~\cite{isenberg2010exploratory,morris2010wesearch}. Second, personal displays may lead to decreased collaboration in co-located settings ~\cite{chung2013investigating, wallace2009investigating}.

When designing CollaboVR, we take the idea of "multiple" displays, displays with "different" angles, and "personal" display into consideration. That leads to the design of different input orientations and the placement of visual aids.

\subsection{Workspace Awareness}
Workspace awareness is the collection of up-to-the-minute knowledge a person uses to capture another's interaction with the workspace~\cite{gutwin1996workspace}. It includes the awareness of others' locations, activities, and intentions relative to the task and to the space. Maintaining workspace awareness enables participants to work together more effectively~\cite{gutwin1998design, gutwin2002descriptive}. To be more specific, workspace awareness played an important role when dealing with: (1) Simplifying the communication, (2) Taking turns and (3) Action prediction ~\cite{gutwin2002descriptive}. So maintaining and enhancing workspace awareness is beneficial to collaboration. One trend is using see-through displays for distributed collaboration. The idea started with Tang and Minneman who designed VideoDraw~\cite{tang1990videodraw} and VideoWhiteBoard~\cite{tang1991videowhiteboard}. Both approaches are two-user experiences. On each side, a video camera was placed to capture the local user and drawing. A projector was attached to show the remote user and drawing on the top of local display. ClearBoard~\cite{ishii1992clearboard} extended the idea and used digital media. Instead of using projector, the media displayed the video feed of remote user and drawing to keep the workspace awareness. Similarly, KinectArms~\cite{genest2013kinectarms} used tangible tabletop as the media and rendered arm of remote user for mixed presence. Furthermore, Jiannan et al.~\cite{li2014interactive} developed FacingBoard with two-sided transparent displays. Same to ClearBoard, the entire upper-body will be displayed to the other participants so the gaze awareness is supported. To keep the gaze interaction, FacingBoard reversed the graphics on the display. However, some column-sensitive content such as text and map became incorrect. To solve this problem, FacingBoard selectively flipped the column-sensitive content individually and adjusted the position of the content. However, when people were pinpointing a specific sub-area within the content, the gaze and the place being pinpointed were inconsistent to all the users. In our system, we proposed different user arrangements to enhance workspace awareness. We also provide the similar face-to-face experience. Differently, we manipulate user's locations to keep the gaze awareness rather than flipping the content and we support more than two people. This will be described in detail later.

// todo
MetaSpace did full body tracking for distributed users to create a better sense of presence~\cite{sra2015metaspace}. 

\subsection{Immersive Collaboration and Communication}
% we need more and more because reviews were complaining the amount
% think about the trend
Much work has been done in collaborative applications in VR/MR.
Some focused on multi-user gaming experiences. SynchronizAR designed a registration algorithm for mobile AR so the participants could join the co-located experience and not need to take extra steps to ensure good-quality positional tracking~\cite{huo2018synchronizar}.
Some focused on developing telepresence and bridging the gap between physical world and virtual world. InForce created a set of novel interaction techniques including haptic feedback for distributed collaboration ~\cite{nakagaki2019inforce}.
Immersive Group-to-Group Telepresence ~\cite{beck2013immersive}
Some designed a collaborative tool for productive work like editing and modeling. SpaceTime focused on improving the experience for two experts collaborating on design work together~\cite{xia2018spacetime}. 
Some put more effort on object manipulation and navigation.
T(ether) is a spatially-aware display system for co-located collaborative manipulation and animation of objects ~\cite{lakatos2014t}. Trackable markers on pads and digital gloves allow participants to use gestures to manipulate objects in space.
Andre et al. designed an application to support object manipulation tasks and scene navigation by ? ~\cite{kunert2019multi}
Some developed the distributed system for remote assistance.
Virtual Replicas for Remote Assistance is a remote collaboration system, allowing a remote expert to guide local users to assemble machine parts by using virtual replicas~\cite{oda2015virtual}.
Others like Geollery~\cite{du2019geollery, du2016social} and ShareVR~\cite{gugenheimer2017sharevr}. Geollery ? social network ? sharevr ? cross-device? might need communication but not strongly rely on.

For collaborative purposes like social network and telepresence, the engagement and sense of being there is the most important. In those scenarios, the communication is not the focus. While for collaborative purposes such as productive work, game, assistance or object manipulation, which require complicated and specific operation and information transfer during the collaboration, the communication performance becomes more important. That is why we want to build a reconfigurable framework to fit different purposes of collaboration.

Then we take a look at the trending of communication with immersive environments.

// fill with old submission and go through chi+cscw+uist for recent 5 years.

Interacting with digital content in a shared space is common too. Three's Company~\cite{tang2010three} explored collaborative activities over connected digital tabletops which support a shared sense of presence among people and artifacts associated with the task. 
Tele-Board~\cite{gumienny2011tele} designed a groupware system specialized in creative working modes using traditional whiteboard and sticky notes in digital form for distributed users.
Hrvoje Benko et al. proposed a unique spatial AR system that combines dynamic projection mapping and multiple perspective views to support face-to-face interaction~\cite{benko2014dyadic}. 
Holoportation demonstrated 3D reconstructions of an entire space, including people~\cite{orts2016holoportation}.
TwinSpace supports deep interconnectivity and flexible mappings between virtual and physical spaces~\cite{reilly2010twinspace}.
Your Place and Mine explored three ways of mapping two differently sized
physical spaces to shared virtual spaces to understand how social presence, togetherness, and movement are influenced~\cite{sra2018}.

%In daily life while speaking to others, we commonly use gestures or visual aids~\cite{tversky2003human} to help present ideas, either subconsciously or purposefully. Visual aids can be drawn on paper, a whiteboard\cite{cherubini2007let}, or a screen via desktop sharing in video conferences. A key task for collaborators is visually, physically, and cognitively following the content being drawn and the people who are speaking with. They need a clear view of the content under discussion and need to be aware of other collaborators' presence when communicating~\cite{ishii1992clearboard}. They should also understand and be able to reason about what is being shown and said. 
%According to Regenbrecht et al.~\cite{regenbrecht2015mutual}, facial interaction like eye contact and mutual gaze has always been recognized as an important requirement for effective visual communications. That suggests it is helpful during communication to look at the person who is talking or at least be aware of the person's location. 
%Oftentimes, participants in a group discussion also need to move around physically to follow the content and each other. In addition, following and presenting content requires the ability to express ideas clearly as well as a fair understanding of the ideas. This may become particularly challenging in discussions revolving around, for example, the placement and design of 3D objects, which cannot easily be visualized using traditional 2D communication media (paper, whiteboard, and so on).

%Tan et al. built a face-to-face presentation system for remote audiences ~\cite{gazeAwareness}. Interacting with digital content in a shared space is common too. 

\section{CollaboVR Overview}
In this section, we present an overview of CollaboVR's system architecture. CollaboVR consists of a protocol which serialize the display data from an application and then de-serialize and render them into graphics. Currently we test CollaboVR with application Chalktalk~\cite{perlin2018chalktalk}. Chalktalk is an open-source digital presentation and communication language. It allows a presenter to create and interact with animated digital sketches on a blackboard-like interface. There are some other smart sketch-based online software such as Autodraw~\cite{Autodraw}, sketch2code~\cite{Sketch2code} and Miro~\cite{Miro} can assist drawing. We chose to use Chalktalk because it is an open-source platform. We can easily define the dataflow between the application and CollaboVR. That means if the API of input and output of the application is accessible, CollaboVR can be easily adapted to use multiple applications as the content provider.

CollaboVR consists of a star network. The network is written in Node.js and C\#. It synchronizes data across devices and supports custom data formats. For CollaboVR, we have two kinds of information: rendering data and user data. In terms of rendering data, we first pass the user input from each client to the server, then the server transmits the user input with the user identifier to the application, next the server receives the serialized display data from the application, finally the server broadcast the display data to each client for rendering. In terms of user data, we currently don't do any process on it so we directly broadcast the user avatar and audio data to each client.

CollaboVR consists of rich interactions on manipulating the drawings. After the clients receive and render the display data from the application, the display data is considered as interactive object in 3D world. We provide manipulation on these objects for users to express their ideas easily. The manipulation includes: duplication, transformation(rotating, scaling and translation), deletion, and colorization.

To deploy CollaboVR, it only requires a VR device running Unity for each client, a server machine running the Node.js (if a VR client needs to be run on a Windows machine, the server code could run on one of the client machines) and a router (optional) which ensures the low latency for data transmission. If a router is not available for setup, all the clients can talk to server through IP address over the Internet. 

% talking about architecture with figures
% Explain the entire pipeline and Chalktalk
\begin{figure*}[htb!]
 \centering
 \includegraphics[width=1.75\columnwidth]{workflow}
 \caption{The workflow of CollaboVR.
 %Chalktalk's content, \textit{sketch} is composed of graphical elements such as point data. 
 // TODO
 %1) \textit{Sketch} data are serialized on the Chalktalk client side every frame and 2) sent as a data array to the Chalktalk server, 3) to the Holojam relay, and then 4) to all Unity clients, where 5) the data are rendered on content board(s). 6) MR user input is sent back through the pipeline to the Chalktalk client and 7) translated into HTML canvas mouse events. 8) Avatar synchronization data are also sent between clients using the Holojam relay.
 }~\label{fig:workflow}
\end{figure*}

Figure ~\ref{fig:workflow} presents the workflow of CollaboVR per frame. First, figure~\ref{fig:workflow}(a) and figure~\ref{fig:workflow}(b) show the third-person perspective view of the VR client before data synchronization. The user in figure~\ref{fig:workflow}(a) is drawing a dinosaur to show what is his or her favorite animal. The user in figure~\ref{fig:workflow}(b) is waiting. Then the data including both users' identifier, avatar information, audio and the drawing input information will be serialized and send to the server. As figure~\ref{fig:workflow}(c) shows, different data will be processed with different label such as \verb|AVATAR_JOIN|, \verb|STYLUS|, \verb|SELECT_OBJ|, \verb|MOVE_OBJ|. The server is behaved as a state-less machine. So the server send the drawing input related data to application API and broadcast avatar related code to all the clients. Later, the application received the drawing input data from the server as figure~\ref{fig:workflow}(d) shows. The application (Chalktalk) will process the input and turn the drawing into 3D objects. We can see that the free-hand drawing dinosaur becomes a 3D dinosaur with pre-designed animation. Our protocol serialized \verb|DisplayData| from application (Chalktalk) and send to the server. The server broadcast \verb|DisplayData| to all the clients. Finally, all the VR clients can see the interactive 3D objects and each other as figure~\ref{fig:workflow}(e) and figure~\ref{fig:workflow}(f) show.

\section{Design Space}
We propose two variables in the design space of CollaboVR: user arrangement and input orientation. Emphasized by the previous work on workspace awareness that maintaining and enhancing workspace awareness enable participants to work together more effectively. We add a dimension that users can change their views of other participants. In other words, they can manipulate the arrangement of other users. 

Inspired by the previous work on collaborative sensemaking, we notice that multiple and shard large displays are good for collaborative work in terms of 2D information. CollaboVR is an immersive 3D graphics world. Instead of "display", we pre-placed multiple "interactive board" in the virtual environment. That means, if the z coordinate of the content is 0, the connect will be placed on the interactive board. If the content has positive or negative z coordinate, user will see that the content is not stitch to the interactive board. The relative coordinate system is the center of the corresponding interactive board. We add a dimension that users can change the input orientation of the interactive board in axis x (from 0$^{\circ}$ to 90$^{\circ}$). Considering the learning curve for the users, we simply provide two edge options: vertical (0$^{\circ}$) and horizontal (90$^{\circ}$) interactive board.

\subsection{User Arrangement}
Currently, we provide two user arrangements: (1) default and (2) mirrored. Default user arrangement means that the virtual environment of each user will be overlapped directly. As figure~\ref{fig:userarrangement} shows, figure~\ref{fig:userarrangement}(a) and figure~\ref{fig:userarrangement}(b) are two top-down view for each client. The green rectangle shows their available tracking area roughly. The blue rectangles show the interactive boards. Figure~\ref{fig:userarrangement}(c) shows the default user arrangement. The clients will see other participants in their original position. For mirrored user arrangement, all the other users' location will be flipped to the other side of the interactive board. See figure~\ref{fig:userarrangement}(d), user2 is in mirrored user arrangement, and user1 is flipped to the other side of the left interactive board because user1 is looking at that board. Spot A is the same content that both users are looking at. After the flipping operation, the gaze direction of user1 and user2 are maintained. Different from FacingBoard~\cite{li2014interactive}, the content is not mirror reversed so the content is still correct to the viewer. In this user arrangement, the users can see each other for better workspace awareness. Figure~\ref{fig:userarrangement}(f) shows how we process multiple users in this setup. Each user will be flipped based on their looking direction.

\begin{figure}[t!]
 \centering
 \includegraphics[width=0.9\columnwidth]{userarrangement.jpg}
 \caption{Design space: user arrangement.
 }~\label{fig:userarrangement}
\end{figure}

\subsection{Input Orientation}
CollaboVR enables the user to adjust the interactive board for input: vertical or horizontal board. By default, the interactive board is vertical as a large display, but in 3D. As figure~\ref{fig:inputorientation}(a) shows, user's experience is close to writing on a white-board. When user turns on the horizontal interactive board, it is close to writing on a tablet or desk, as figure~\ref{fig:inputorientation}(b) shows. For other users who are not writing, the content will be rendered real-timely on the vertical board. By doing this we avoid the situation that the content is not readable for all the users around a table. Considering the reach distance when writing on a horizontal plane is different from on a vertical plane, we adjust the scale of the horizontal board. When user is writing on the horizontal board, he or she is free to look at the personal horizontal board or the shared vertical board. To enhance the awareness of where the user is writing on, we render the projection point of user's controller as a 3D cursor.

\begin{figure}[b!]
 \centering
 \includegraphics[width=0.9\columnwidth]{inputorientation.jpg}
 \caption{Design space: input orientation.
 }~\label{fig:inputorientation}
\end{figure}

\section{System Implementation}
To build CollaboVR, we implement a network framework and a flexible protocol, a calibration approach for co-located users and user interface for drawing manipulation.

\subsection{Network and Protocol}
The network is a star network using UDP. The reason we chose UDP is that we value low-latency more than the accuracy. The server-side code is written in Node.js and the client code is written in Node.js and Unity C\#. We defined \textit{synchronizable object}: an object needs to synchronized each frame for the client who registered it. Each synchronizable object has a label and data stream. The label is a unique identifier for client to register. The data stream includes the frequency of sending this object and the real-time data. We provide two kinds of frequency in the system: one-time and per frame. One-time synchronizable object is actually a command. It doesn't happen for each frame and not need to be synchronized for each frame. For command object, we use two-way handshaking. The client sends the object to the server, the server returns an object including acknowledgement back to the client, then the client de-registers the object with this label. Per frame synchronizable object could be the current avatar representation, the audio data or the display data from the application. We design a protocol to wrap all the display data. The data protocol includes information of all the rendered points by encoding the attributes such as position, width and color. Each client de-serialize the data from the server and render the points as lines and meshes.

\subsection{Calibration for Co-located Scenarios}
CollaboVR is working for both co-located and distributed scenarois. For distributed users, we simply overlap their virtual environments because they don't have any spatial relationship. For co-located users, we need to calibrate all the users so they are all in the same coordinate system. The key idea for calibration is that different clients should have a shared proxy. For example, all the co-located users can see the same image in that environment. Vuforia~\cite{Vuforia} is widely used for image recognition and tracking. Similarly, a shared map is helpful too~\cite{Hololens}. Here we use Vive Pro as the co-located device. The shared proxy is the Vive base station. Each machine running Vive can retrieve the transformation information of the base station. Because each machine has their own coordinate systems, we will have the same mount of the position and rotation of base station. We pre-chose one base station as the proxy based on the unique serial number. Then we use the first client which connected to the server as the reference node. All the following clients will apply the inverse matrix between the base station of reference node and their own base station to their VR environment. See figure~\ref{vivepro}, user1 is drawing a physics model. The left image shows the first-player perspective view from user2 and the right image shows a front view of the environment.

\begin{figure}[tb!]
 \centering
 \includegraphics[width=0.9\columnwidth]{vivepro.jpg}
 \caption{Calibration results for co-located users.
 }~\label{fig:vivepro}
\end{figure}

\subsection{Drawing Manipulation}
CollaboVR includes a user interface for users to manipulate the objects after drawing. We provide the functionality of duplication, transforming, deletion and colorizing. To achieve this, we design a pie menu triggered by the controller. Here is the workflow for manipulation: first, we place the controller hovering over the drawing of interest; second, press the thumbstick of the dominate controller; then, the pie menu shows up as figure~\ref{fig:userinterface}; Move the thumbstick to select the specific menu; Apply corresponding movement in terms of the command and release the thumbstick. If the menu is deletion, the operation applies immediately after release. If the menu is transformation, user needs to move the controller to complete rotation, scaling and translation. If the menu is copy, the duplicated object will be placed at the position where the user releases thumbstick. In addition, we enable colorization through another button. User can drag the color from the color palette to any drawing like world builder\footnote{\url{https://www.youtube.com/watch?v=FheQe8rflWQ}}. Colorization is triggered by button one as figure~\ref{fig:userinterface} shows. Considering the system is working identical to left-hand users and right-hand users, button two is designed to switch the commands between two controllers.

\begin{figure}[tb!]
 \centering
 \includegraphics[width=0.9\columnwidth]{userinterface.jpg}
 \caption{User interface for drawing manipulation.
 }~\label{fig:userinterface}
\end{figure}

\section{Use Cases}
CollaboVR is designed as a reconfigurable framework for users to communicate in VR. Here we envision the potential user cases for CollaboVR.

\subsubsection{Daily Life Schedule}

\subsubsection{Presentation}

\subsubsection{Spatial Arrangement}

\subsubsection{Item Design}

\section{User Study: System Evaluation}
In this study, we evaluated the interaction cycle, design variables and prototype implementation of CollaboVR. We were interested in how participants use the system. During the study, we collected primarily qualitative feedback to gain insight into the experience of using the system.
\subsection{Tasks and Procedure}
[...]
\subsubsection{Living room design}
\subsubsection{Semi-structured interview}
Upon completion of all the configurations, we presented users with a set of statements and asked them to rate how much they agreed with each of them, on a 7-point Likert scale. We then went into a semi-structured interview asking about their experience, trying to gain insight into the usability of the system.
\subsection{Participants}
We recruited a total of 12 participants ( females; age range: ?? - ??, with an average of ??? and standard deviation of ??) via campus email lists and word-of-mouth. None of the participants had been involved with this project before.

\subsection{Results and Discussion} 
// remember to put a bar-chart diagram
\subsubsection{Usability // Overall}
\subsubsection{User Representation}
\subsubsection{Input Orientations}


\section{Limitation and Future Work}

\section{Conclusion}


%\begin{figure}
%\centering
  %\includegraphics[width=0.9\columnwidth]{figures/sigchi-logo}
  %\caption{Insert a caption below each figure. Do not alter the
    %Caption style.  One-line captions should be centered; multi-line
    %should be justified. }~\label{fig:figure1}
%\end{figure}

%\subsection{References and Citations}
%(e.g., ``[Borriello, personal communication]'').

% Use a numbered list of references at the end of the article, ordered
% alphabetically by first author, and referenced by numbers in
% brackets~\cite{ethics, Klemmer:2002:WSC:503376.503378,
%   Mather:2000:MUT, Zellweger:2001:FAO:504216.504224}. For papers from
% conference proceedings, include the title of the paper and an
% abbreviated name of the conference (e.g., for Interact 2003
% proceedings, use \textit{Proc. Interact 2003}). Do not include the
% location of the conference or the exact date; do include the page
% numbers if available. See the examples of citations at the end of this
% document. Within this template file, use the \texttt{References} style
% for the text of your citation.

% Your references should be published materials accessible to the
% public.  Internal technical reports may be cited only if they are
% easily accessible (i.e., you provide the address for obtaining the
% report within your citation) and may be obtained by any reader for a
% nominal fee.  Proprietary information may not be cited. Private
% communications should be acknowledged in the main text, not referenced
% (e.g., ``[Robertson, personal communication]'').

%\begin{table}
  %\centering
  %\begin{tabular}{l r r r}
    %% \toprule
    %& & \multicolumn{2}{c}{\small{\textbf{Test Conditions}}} \\
    %\cmidrule(r){3-4}
    %{\small\textit{Name}}
    %& {\small \textit{First}}
      %& {\small \textit{Second}}
    %& {\small \textit{Final}} \\
    %\midrule
    %Marsden & 223.0 & 44 & 432,321 \\
    %Nass & 22.2 & 16 & 234,333 \\
    %Borriello & 22.9 & 11 & 93,123 \\
    %Karat & 34.9 & 2200 & 103,322 \\
    %% \bottomrule
  %\end{tabular}
  %\caption{Table captions should be placed below the table. We
    %recommend table lines be 1 point, 25\% black. Minimize use of
    %table grid lines.}~\label{tab:table1}
%\end{table}


%Place figures and tables at the top or bottom of the appropriate
%column or columns, on the same page as the relevant text (see
%Figure~\ref{fig:figure1}). A figure or table may extend across both
%columns to a maximum width of 17.78 cm (7 in.).

%\begin{figure*}
  %\centering
  %\includegraphics[width=1.75\columnwidth]{figures/map}
  %\caption{In this image, the map maximizes use of space. You can make
    %figures as wide as you need, up to a maximum of the full width of
    %both columns. Note that \LaTeX\ tends to render large figures on a
    %dedicated page. Image: \ccbynd~ayman on
    %Flickr.}~\label{fig:figure2}
%\end{figure*}

%Captions should be Times New Roman or Times Roman 9-point bold.  They
%should be numbered (e.g., ``Table~\ref{tab:table1}'' or
%``Figure~\ref{fig:figure1}''), centered (if one line) otherwise justified, and placed beneath the figure or table.  Please note that the words ``Figure'' and ``Table'' should
%be spelled out (e.g., ``Figure'' rather than ``Fig.'') wherever they
%occur. Figures, like Figure~\ref{fig:figure2}, may span columns and
%all figures should also include alt text for improved accessibility.

%When possible, include a vector formatted graphic (i.e. PDF or EPS).
%When including bitmaps,  use an image editing tool to resize the image
%at the appropriate printing resolution (usually 300 dpi).

%Quotations may be italicized when \textit{``placed inline''}.

%\begin{quote}
%Longer quotes, when placed in their own paragraph, need not be
%italicized or in quotation marks when indented.  
%\end{quote}

%\begin{itemize}
%\item Write in a straightforward style.
%\item Try to avoid long or complex sentence structures.
%\item Briefly define or explain all technical terms that may be
  %unfamiliar to readers.
%\item Be careful with the use of gender-specific pronouns (he, she)
  %and other gendered words (chairman, manpower, man-months). Use
  %inclusive language that is gender-neutral (e.g., she or he, they,
  %s/he, chair, staff, staff-hours, person-years). See the
%\end{itemize}

%\begin{enumerate}
%\item Add alternative text to all figures
%\item Mark table headings
%\item Add tags to the PDF
%\item Verify the default language
%\item Set the tab order to ``Use Document Structure''
%\end{enumerate}
%For more information and links to instructions and resources, please
%see: \url{http://chi2016.acm.org/accessibility}.  The
%\texttt{{\textbackslash}hyperref} package allows you to create well tagged PDF files,
%please see the preamble of this template for an example.

%We recommend that you produce a PDF version of your submission well
%before the final deadline.  Your PDF file must be ACM DL
%Compliant. The requirements for an ACM Compliant PDF are available at:
%{\url{http://www.scomminc.com/pp/acmsig/ACM-DL-pdfs-requirements.htm}}.

%Test your PDF file by viewing or printing it with the same software we
%will use when we receive it, Adobe Acrobat Reader Version 10. This is
%widely available at no cost. 

%\section{Acknowledgments}

%Sample text: We thank all the volunteers, and all publications support
%and staff, who wrote and provided helpful comments on previous
%versions of this document.

% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
\balance{}

% BALANCE COLUMNS
\balance{}

% REFERENCES FORMAT
% References must be the same font size as other body text.
\bibliographystyle{SIGCHI-Reference-Format}
\bibliography{sample}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
